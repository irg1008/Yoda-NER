{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zapatillas La Sportiva Ultra Raptor Hombre Neg...</td>\n",
       "      <td>Negro/Verde</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calcetines running Compressport Run High V3 Bl...</td>\n",
       "      <td>Blanco/Rosa</td>\n",
       "      <td>45 - 48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZAPATILLAS CHIRUCA TASMANIA 10 GORE-TEX GRIS 4...</td>\n",
       "      <td>Gris</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZAPATILLAS CHIRUCA TASMANIA 10 GORE-TEX GRIS 4...</td>\n",
       "      <td>Gris</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Botas Boreal APACHE GRIS 47 Gris</td>\n",
       "      <td>Gris</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        color     size\n",
       "0  Zapatillas La Sportiva Ultra Raptor Hombre Neg...  Negro/Verde       46\n",
       "1  Calcetines running Compressport Run High V3 Bl...  Blanco/Rosa  45 - 48\n",
       "2  ZAPATILLAS CHIRUCA TASMANIA 10 GORE-TEX GRIS 4...         Gris       41\n",
       "3  ZAPATILLAS CHIRUCA TASMANIA 10 GORE-TEX GRIS 4...         Gris       40\n",
       "4                   Botas Boreal APACHE GRIS 47 Gris         Gris       47"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/features.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.create_corpus import parse_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Zapatillas': 'O', 'La': 'O', 'Sportiva': 'O', 'Ultra': 'O', 'Raptor': 'O', 'Hombre': 'O', 'Negro': 'B-color', 'Verde': 'B-color', '46': 'B-size', 'Negro/Verde': 'O'}\n"
     ]
    }
   ],
   "source": [
    "corpus = parse_corpus(data)\n",
    "print(corpus[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(*lists, unique=False):\n",
    "    flattened = [item for l in lists for sublist in l for item in sublist]\n",
    "    return list(set(flattened)) if unique else flattened\n",
    "\n",
    "\n",
    "def get_len(*lists) -> int:\n",
    "    return sum(len(row) for l in lists for row in l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_and_labels(corpus):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for line in corpus:\n",
    "        x = list(line.keys())\n",
    "        y = list(line.values())\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "    def get_vector(x, surplus=0):\n",
    "        flattened = flatten(x, unique=True)\n",
    "        idx = {word: i + surplus for i, word in enumerate(flattened)}\n",
    "        vector = [[idx[word] for word in row] for row in x]\n",
    "        return vector, len(flattened)\n",
    "\n",
    "    vector_X, num_x = get_vector(X, surplus=1)\n",
    "    vector_Y, num_y = get_vector(Y)\n",
    "\n",
    "    return vector_X, vector_Y, num_x, num_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "X, Y, _, num_tags = get_inputs_and_labels(corpus)\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1226, 916, 447, 954, 85, 1275, 121, 1268, 24, 133] [0, 0, 0, 0, 0, 0, 2, 2, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0], Y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17411\n"
     ]
    }
   ],
   "source": [
    "vocab_size = get_len(X)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487 372\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "print(len(X_train), len(X_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, Y, batch_size=4, pad=None, shuffle=True):\n",
    "    \"\"\"Generate batches of data.\n",
    "    Args:\n",
    "        X (list): List of sentences.\n",
    "        Y (list): List of labels.\n",
    "        pad_value: Value use for padding. Will be removed on trainning. Necessary for regular shaped batches.\n",
    "        batch_size (int, optional): Size of the batch. Defaults to 4.\n",
    "        shuffle (bool, optional): Shuffle data. Defaults to True.\n",
    "    Yields:\n",
    "        tuple: Batch of data.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        data = list(zip(X, Y))\n",
    "        rnd.shuffle(data)\n",
    "        X, Y = zip(*data)\n",
    "\n",
    "    max_input_size = max(len(x) for x in X)\n",
    "\n",
    "    def set(batch_idx, global_idx, batch, data):\n",
    "        item = data[global_idx]\n",
    "        batch[i, : len(item)] = item\n",
    "\n",
    "    data_idx = 0\n",
    "    while data_idx < len(X):\n",
    "        x = np.full((batch_size, max_input_size), fill_value=pad)\n",
    "        y = x.copy()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            set(i, data_idx, x, X)\n",
    "            set(i, data_idx, y, Y)\n",
    "\n",
    "            data_idx += 1\n",
    "            if data_idx >= len(X):\n",
    "                break\n",
    "\n",
    "        yield x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.models import reformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NERModel(tags, vocab_size, d_model=50):\n",
    "    model = tl.Serial(\n",
    "        reformer.Reformer(vocab_size, d_model, ff_activation=tl.LogSoftmax),\n",
    "        tl.Dense(tags),\n",
    "        tl.LogSoftmax(),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel(tags=num_tags, vocab_size=vocab_size)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "from trax.data.inputs import add_loss_weights\n",
    "from trax import optimizers as opts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_gen = batch_generator(X_train, Y_train, pad=vocab_size)\n",
    "val_batch_gen = batch_generator(X_val, Y_val, pad=vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = add_loss_weights(train_batch_gen, id_to_mask=vocab_size)\n",
    "val_gen = add_loss_weights(val_batch_gen, id_to_mask=vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_generator, val_generator, train_steps=1, output_dir=\"model\"\n",
    "):\n",
    "    train_task = training.TrainTask(\n",
    "        train_generator,\n",
    "        loss_layer=tl.CrossEntropyLoss(),\n",
    "        optimizer=opts.Adam(0.01),\n",
    "        n_steps_per_checkpoint=10,\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=val_generator,\n",
    "        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    "        n_eval_batches=10,\n",
    "    )\n",
    "\n",
    "    training_loop = training.Loop(\n",
    "        model,\n",
    "        train_task,\n",
    "        eval_tasks=[eval_task],\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    training_loop.run(n_steps=train_steps)\n",
    "    return training_loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()\n  In call to configurable 'EvalTask' (<class 'trax.supervised.training.EvalTask'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [123], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m training_loop \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [122], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_generator, val_generator, train_steps, output_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[1;32m      2\u001b[0m     model, train_generator, val_generator, train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m ):\n\u001b[1;32m      4\u001b[0m     train_task \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mTrainTask(\n\u001b[1;32m      5\u001b[0m         train_generator,\n\u001b[1;32m      6\u001b[0m         loss_layer\u001b[38;5;241m=\u001b[39mtl\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[1;32m      7\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mopts\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.01\u001b[39m),\n\u001b[1;32m      8\u001b[0m         n_steps_per_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      9\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0m     eval_task \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEvalTask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabeled_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     training_loop \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mLoop(\n\u001b[1;32m     18\u001b[0m         model,\n\u001b[1;32m     19\u001b[0m         train_task,\n\u001b[1;32m     20\u001b[0m         eval_tasks\u001b[38;5;241m=\u001b[39m[eval_task],\n\u001b[1;32m     21\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     training_loop\u001b[38;5;241m.\u001b[39mrun(n_steps\u001b[38;5;241m=\u001b[39mtrain_steps)\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m in scope \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scope_str) \u001b[39mif\u001b[39;00m scope_str \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[39m=\u001b[39m err_str\u001b[39m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m utils\u001b[39m.\u001b[39;49maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[39m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(exception)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mraise\u001b[39;00m proxy\u001b[39m.\u001b[39mwith_traceback(exception\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1177\u001b[0m, in \u001b[0;36mEvalTask.__init__\u001b[0;34m(self, labeled_data, metrics, metric_names, n_eval_batches, sample_batch, export_prefix)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_names \u001b[39m=\u001b[39m metric_names \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_names()\n\u001b[1;32m   1175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_eval_batches \u001b[39m=\u001b[39m n_eval_batches  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m-> 1177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_batch \u001b[39m=\u001b[39m sample_batch \u001b[39mor\u001b[39;00m \u001b[39mnext\u001b[39;49m(labeled_data)\n\u001b[1;32m   1178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_init_values()\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/data/inputs.py:864\u001b[0m, in \u001b[0;36madd_loss_weights\u001b[0;34m(generator, id_to_mask)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39m@debug_data_pipeline\u001b[39m\u001b[39m.\u001b[39mdebug_pipeline\n\u001b[1;32m    845\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_loss_weights\u001b[39m(generator, id_to_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    846\u001b[0m   \u001b[39m\"\"\"Add weights to inputs without weights and masks by id if requested.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[1;32m    848\u001b[0m \u001b[39m  The generator stream is augmented in the following way:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39m    Examples from the augmented stream.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m   \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m generator:\n\u001b[1;32m    865\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(example) \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(example) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    866\u001b[0m       \u001b[39massert\u001b[39;00m id_to_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mCannot automatically mask this stream.\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[0;32mIn [115], line 17\u001b[0m, in \u001b[0;36mbatch_generator\u001b[0;34m(X, Y, batch_size, pad, shuffle)\u001b[0m\n\u001b[1;32m     14\u001b[0m     rnd\u001b[38;5;241m.\u001b[39mshuffle(data)\n\u001b[1;32m     15\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 17\u001b[0m max_input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(batch_idx, global_idx, batch, data):\n\u001b[1;32m     20\u001b[0m     item \u001b[38;5;241m=\u001b[39m data[global_idx]\n",
      "Cell \u001b[0;32mIn [115], line 17\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     rnd\u001b[38;5;241m.\u001b[39mshuffle(data)\n\u001b[1;32m     15\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 17\u001b[0m max_input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(batch_idx, global_idx, batch, data):\n\u001b[1;32m     20\u001b[0m     item \u001b[38;5;241m=\u001b[39m data[global_idx]\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()\n  In call to configurable 'EvalTask' (<class 'trax.supervised.training.EvalTask'>)"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "output_dir = \"../models\"\n",
    "\n",
    "training_loop = train_model(model, train_gen, val_gen, epochs, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6042048dd5ff1a956581b1cb53ad33b246ccdcf12080002e9fbd5f79ce38e4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
