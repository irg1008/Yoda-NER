{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Becotray 51 X 40 X 17 Cm Azul Oferta</td>\n",
       "      <td>BECO</td>\n",
       "      <td>azul</td>\n",
       "      <td>17;17 cm;51 x 40 x 17 cm;40;51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Becotray 51 X 40 X 17 Cm Marr贸n Oferta</td>\n",
       "      <td>BECO</td>\n",
       "      <td>marr贸n</td>\n",
       "      <td>17;17 cm;51 x 40 x 17 cm;40;51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heno Home Friends Menta/Escaramujo 0,5Kg Oferta</td>\n",
       "      <td>COMINTER</td>\n",
       "      <td>menta</td>\n",
       "      <td>0,5kg;0,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seresto Collar Antiparasitario Perro - 8Kg / 38Cm</td>\n",
       "      <td>BAYER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38cm;8kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seresto Collar Antiparasitario Perro + 8 Kg / ...</td>\n",
       "      <td>BAYER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8 kg;70cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     brand   color  \\\n",
       "0               Becotray 51 X 40 X 17 Cm Azul Oferta      BECO    azul   \n",
       "1             Becotray 51 X 40 X 17 Cm Marr贸n Oferta      BECO  marr贸n   \n",
       "2    Heno Home Friends Menta/Escaramujo 0,5Kg Oferta  COMINTER   menta   \n",
       "3  Seresto Collar Antiparasitario Perro - 8Kg / 38Cm     BAYER     NaN   \n",
       "4  Seresto Collar Antiparasitario Perro + 8 Kg / ...     BAYER     NaN   \n",
       "\n",
       "                             size  \n",
       "0  17;17 cm;51 x 40 x 17 cm;40;51  \n",
       "1  17;17 cm;51 x 40 x 17 cm;40;51  \n",
       "2                        0,5kg;0,  \n",
       "3                        38cm;8kg  \n",
       "4                       8 kg;70cm  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/features.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.create_corpus import parse_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Heno': 'O', 'Home': 'O', 'Friends': 'O', 'Menta': 'B-color', '/': 'O', 'Escaramujo': 'O', '0,5Kg': 'O', 'Oferta': 'O'}\n"
     ]
    }
   ],
   "source": [
    "corpus = parse_corpus(data)\n",
    "print(corpus[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.inputs import get_vectors, flatten, get_inputs_and_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = get_inputs_and_labels(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/inputs.jsonl\", \"w\") as f:\n",
    "    for _a, _b in zip(a, b):\n",
    "        f.write(json.dumps({\"tokens\": _a, \"tags\": _b}) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, _, num_tags = get_vectors(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[786, 7, 1712, 799, 1295, 365, 222, 1952] [4, 4, 4, 4, 4, 4, 5, 4]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(X[0], Y[0])\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate vocab size and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\Yoda\\NER\\model\\trax\\src\\training.ipynb Celda 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/src/training.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vocab \u001b[39m=\u001b[39m flatten(corpus)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/src/training.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(vocab)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/src/training.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(vocab_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flatten' is not defined"
     ]
    }
   ],
   "source": [
    "vocab = flatten(corpus)\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u0445' in position 4: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\Yoda\\NER\\model\\trax\\src\\training.ipynb Celda 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/src/training.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49msavetxt(\u001b[39m\"\u001b[39;49m\u001b[39m../data/vocab.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, vocab, fmt\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:1565\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1561\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1562\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMismatch between array dtype (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m) and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1563\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mformat specifier (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1564\u001b[0m                             \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(X\u001b[39m.\u001b[39mdtype), \u001b[39mformat\u001b[39m)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m-> 1565\u001b[0m         fh\u001b[39m.\u001b[39;49mwrite(v)\n\u001b[0;32m   1567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(footer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1568\u001b[0m     footer \u001b[39m=\u001b[39m footer\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m comments)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_encode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,encoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u0445' in position 4: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"../data/vocab.txt\", vocab, fmt=\"'%s'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/sklearn/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tags\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_X_y\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/sklearn/utils/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmurmurhash\u001b[39;00m \u001b[39mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclass_weight\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/scipy/sparse/__init__.py:283\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_arrays\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    279\u001b[0m     csr_array, csc_array, lil_array, dok_array, coo_array, dia_array, bsr_array\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    282\u001b[0m \u001b[39m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m csgraph\n\u001b[1;32m    285\u001b[0m \u001b[39m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    287\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    288\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    289\u001b[0m )\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/scipy/sparse/csgraph/__init__.py:182\u001b[0m\n\u001b[1;32m    154\u001b[0m __docformat__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrestructuredtext en\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mconnected_components\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    157\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mlaplacian\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    158\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mshortest_path\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mcsgraph_to_masked\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    180\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mNegativeCycleError\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 182\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_laplacian\u001b[39;00m \u001b[39mimport\u001b[39;00m laplacian\n\u001b[1;32m    183\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_shortest_path\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    185\u001b[0m     NegativeCycleError\n\u001b[1;32m    186\u001b[0m )\n\u001b[1;32m    187\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_traversal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    188\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    189\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    190\u001b[0m )\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m isspmatrix\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     10\u001b[0m \u001b[39m###############################################################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Graph laplacian\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlaplacian\u001b[39m(\n\u001b[1;32m     13\u001b[0m     csgraph,\n\u001b[1;32m     14\u001b[0m     normed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     symmetrized\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m ):\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/scipy/sparse/linalg/__init__.py:120\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dsolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39miterative\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mminres\u001b[39;00m \u001b[39mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlgmres\u001b[39;00m \u001b[39mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/scipy/sparse/linalg/_isolve/iterative.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextwrap\u001b[39;00m \u001b[39mimport\u001b[39;00m dedent\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _iterative\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m make_system\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487 372\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "print(len(X_train), len(X_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:54:40.019222: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-22 13:54:47.574423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-22 13:54:47.574879: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-22 13:54:47.574891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.model import NERModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel(tags=num_tags, vocab_size=vocab_size)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.batch import batch_generator\n",
    "from trax.data.inputs import add_loss_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_value = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_gen = batch_generator(X_train, Y_train, pad=mask_value)\n",
    "val_batch_gen = batch_generator(X_val, Y_val, pad=mask_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = add_loss_weights(train_batch_gen, id_to_mask=mask_value)\n",
    "val_gen = add_loss_weights(val_batch_gen, id_to_mask=mask_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "from trax import optimizers as opts\n",
    "from trax import layers as tl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_generator, val_generator, train_steps=1, output_dir=\"model\"\n",
    "):\n",
    "    train_task = training.TrainTask(\n",
    "        train_generator,\n",
    "        loss_layer=tl.CrossEntropyLoss(),\n",
    "        optimizer=opts.Adam(0.01),\n",
    "        n_steps_per_checkpoint=10,\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=val_generator,\n",
    "        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    "        n_eval_batches=10,\n",
    "    )\n",
    "\n",
    "    training_loop = training.Loop(\n",
    "        model,\n",
    "        tasks=[train_task],\n",
    "        eval_tasks=[eval_task],\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    training_loop.run(n_steps=train_steps)\n",
    "    return training_loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/jax/_src/lib/xla_bridge.py:550: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "2022-09-22 13:58:58.578240: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] \n",
      "********************************\n",
      "[Compiling module jit_single_device_update_fn.98] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "2022-09-22 14:12:37.804781: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 15m39.226732796s\n",
      "\n",
      "********************************\n",
      "[Compiling module jit_single_device_update_fn.98] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 55166769\n",
      "Step      1: Ran 1 train steps in 981.87 secs\n",
      "Step      1: train CrossEntropyLoss |  3.00129676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: eval  CrossEntropyLoss |  3.19672992\n",
      "Step      1: eval          Accuracy |  0.71199360\n",
      "\n",
      "Step     10: Ran 9 train steps in 21.69 secs\n",
      "Step     10: train CrossEntropyLoss |  5.36177540\n",
      "Step     10: eval  CrossEntropyLoss |  4.82323470\n",
      "Step     10: eval          Accuracy |  0.70426232\n",
      "\n",
      "Step     20: Ran 10 train steps in 22.28 secs\n",
      "Step     20: train CrossEntropyLoss |  3.33057261\n",
      "Step     20: eval  CrossEntropyLoss |  4.04009326\n",
      "Step     20: eval          Accuracy |  0.71858896\n",
      "\n",
      "Step     30: Ran 10 train steps in 22.64 secs\n",
      "Step     30: train CrossEntropyLoss |  2.95643616\n",
      "Step     30: eval  CrossEntropyLoss |  1.96336987\n",
      "Step     30: eval          Accuracy |  0.12207776\n",
      "\n",
      "Step     40: Ran 10 train steps in 22.80 secs\n",
      "Step     40: train CrossEntropyLoss |  1.40213001\n",
      "Step     40: eval  CrossEntropyLoss |  0.59534968\n",
      "Step     40: eval          Accuracy |  0.69862046\n",
      "\n",
      "Step     50: Ran 10 train steps in 22.48 secs\n",
      "Step     50: train CrossEntropyLoss |  0.74997789\n",
      "Step     50: eval  CrossEntropyLoss |  0.68407939\n",
      "Step     50: eval          Accuracy |  0.71225055\n",
      "\n",
      "Step     60: Ran 10 train steps in 23.49 secs\n",
      "Step     60: train CrossEntropyLoss |  0.48969260\n",
      "Step     60: eval  CrossEntropyLoss |  0.50903030\n",
      "Step     60: eval          Accuracy |  0.71306412\n",
      "\n",
      "Step     70: Ran 10 train steps in 22.91 secs\n",
      "Step     70: train CrossEntropyLoss |  0.49145699\n",
      "Step     70: eval  CrossEntropyLoss |  0.41964708\n",
      "Step     70: eval          Accuracy |  0.67233398\n",
      "\n",
      "Step     80: Ran 10 train steps in 22.63 secs\n",
      "Step     80: train CrossEntropyLoss |  0.52143443\n",
      "Step     80: eval  CrossEntropyLoss |  0.44814070\n",
      "Step     80: eval          Accuracy |  0.71772014\n",
      "\n",
      "Step     90: Ran 10 train steps in 22.89 secs\n",
      "Step     90: train CrossEntropyLoss |  0.50155783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1388: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return [f for f in flat if f is not None and f is not ()]  # pylint: disable=literal-comparison\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1388: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return [f for f in flat if f is not None and f is not ()]  # pylint: disable=literal-comparison\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1388: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return [f for f in flat if f is not None and f is not ()]  # pylint: disable=literal-comparison\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1388: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return [f for f in flat if f is not None and f is not ()]  # pylint: disable=literal-comparison\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1388: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return [f for f in flat if f is not None and f is not ()]  # pylint: disable=literal-comparison\n",
      "/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1388: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return [f for f in flat if f is not None and f is not ()]  # pylint: disable=literal-comparison\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m training_loop \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [19], line 24\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_generator, val_generator, train_steps, output_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m eval_task \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mEvalTask(\n\u001b[1;32m     12\u001b[0m     labeled_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[1;32m     13\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[tl\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), tl\u001b[38;5;241m.\u001b[39mAccuracy()],\n\u001b[1;32m     14\u001b[0m     n_eval_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m training_loop \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mLoop(\n\u001b[1;32m     18\u001b[0m     model,\n\u001b[1;32m     19\u001b[0m     train_task,\n\u001b[1;32m     20\u001b[0m     eval_tasks\u001b[38;5;241m=\u001b[39m[eval_task],\n\u001b[1;32m     21\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m training_loop\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:483\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, n_steps)\u001b[0m\n\u001b[1;32m    474\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    475\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_training_progress(\n\u001b[1;32m    476\u001b[0m     task\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks[task_index],\n\u001b[1;32m    477\u001b[0m     total_loss\u001b[39m=\u001b[39mloss_acc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m     summary_writer\u001b[39m=\u001b[39mtrain_summary_writers[task_index],\n\u001b[1;32m    482\u001b[0m )\n\u001b[0;32m--> 483\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_evals(eval_summary_writers)\n\u001b[1;32m    484\u001b[0m loss_acc, step_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m    485\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:759\u001b[0m, in \u001b[0;36mLoop.run_evals\u001b[0;34m(self, summary_writers)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_batches):\n\u001b[1;32m    758\u001b[0m   rng \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_rng()\n\u001b[0;32m--> 759\u001b[0m   batch \u001b[39m=\u001b[39m eval_task\u001b[39m.\u001b[39;49mnext_batch()\n\u001b[1;32m    760\u001b[0m   metric_values, _ \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39mmetrics_fn(\n\u001b[1;32m    761\u001b[0m       batch, metrics_weights, metrics_state, rng)\n\u001b[1;32m    762\u001b[0m   sums \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m metric_values\n",
      "File \u001b[0;32m/mnt/c/Users/Ivan/Documents/Projects/Yoda/NER/model/trax/venv/lib/python3.9/site-packages/trax/supervised/training.py:1190\u001b[0m, in \u001b[0;36mEvalTask.next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext_batch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1189\u001b[0m   \u001b[39m\"\"\"Returns one batch of labeled data: a tuple of input(s) plus label.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_labeled_data)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "output_dir = \"../models\"\n",
    "\n",
    "training_loop = train_model(model, train_gen, val_gen, epochs, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fefe1bf480c11bf003fba226430f9cc6591c2a11b0f80c22005b6e46c2183a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
